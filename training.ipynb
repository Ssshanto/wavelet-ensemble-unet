{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.8 (you have 1.4.7). Upgrade using: pip install --upgrade albumentations\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "from albumentations.augmentations import transforms, Normalize\n",
    "from albumentations import Flip, RandomRotate90, Resize\n",
    "from albumentations.core.composition import Compose, OneOf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import argparse\n",
    "\n",
    "import models\n",
    "import metrics\n",
    "import utils\n",
    "from train import *\n",
    "from data import BUSIDataset\n",
    "\n",
    "config = argparse.Namespace()\n",
    "\n",
    "config.model = 'Wavelet_UNet_All'\n",
    "\n",
    "config.SIZE = 128\n",
    "config.batch_size = 32\n",
    "config.num_workers = 8\n",
    "config.n_channels = 1\n",
    "config.lr = 0.0001\n",
    "config.min_lr = 0.00001\n",
    "config.epochs = 50\n",
    "config.early_stopping = 50\n",
    "config.patience = config.early_stopping\n",
    "config.base_dir = ''\n",
    "config.root_path = os.path.join(config.base_dir, 'breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/')\n",
    "config.semantic = False\n",
    "config.device = torch.device('cuda:0')\n",
    "config.classes = ['normal', 'benign', 'malignant']\n",
    "config.labels = []\n",
    "config.num_classes = 3 if config.semantic else 1\n",
    "config.loss = 'BCEDiceLoss'\n",
    "config.optimizer = 'Adam'\n",
    "config.scheduler = 'CosineAnnealingLR'\n",
    "config.weight_decay = 1e-4\n",
    "config.momentum = 0.9\n",
    "config.nesterov = False\n",
    "config.seed = 4\n",
    "\n",
    "if config.semantic:\n",
    "    config.labels = config.classes\n",
    "else:\n",
    "    config.labels = ['cancer']\n",
    "\n",
    "# write a function that sets the seed of all the libraries\n",
    "def set_seed():\n",
    "    torch.manual_seed(config.seed)\n",
    "    np.random.seed(config.seed)\n",
    "    random.seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(config):\n",
    "    if config.model is not None and not os.path.exists('models/%s' % config.model):\n",
    "        os.makedirs('models/%s' % config.model)\n",
    "\n",
    "    print('-' * 20)\n",
    "    for key, value in config.__dict__.items():\n",
    "        print('%s: %s' % (key, value))\n",
    "    print('-' * 20)\n",
    "\n",
    "\n",
    "    criterion = metrics.__dict__[config.loss]().cuda()\n",
    "    model = models.__dict__[config.model](n_channels=config.n_channels,\n",
    "                                            n_classes=config.num_classes).cuda()\n",
    "\n",
    "\n",
    "    summary(model, (config.n_channels, config.SIZE, config.SIZE))\n",
    "\n",
    "    params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    num_params = sum([p.numel() for p in model.parameters()])\n",
    "\n",
    "    if config.optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(\n",
    "            params, lr=config.lr, weight_decay=config.weight_decay)\n",
    "    elif config.optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(params, lr=config.lr, momentum=config.momentum,\n",
    "                                nesterov=config.nesterov, weight_decay=config.weight_decay)\n",
    "\n",
    "    if config.scheduler == 'CosineAnnealingLR':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, T_max=config.epochs, eta_min=config.min_lr)\n",
    "    elif config.scheduler == 'ReduceLROnPlateau':\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, factor=config.factor, patience=config.patience,\n",
    "                                                    verbose=1, min_lr=config.min_lr)\n",
    "    else:\n",
    "        scheduler = None\n",
    "\n",
    "    image_paths, mask_paths = utils.load_dataset(config.root_path)\n",
    "    print(f\"Total Images: {len(image_paths)}, Masks: {len(mask_paths)}\")\n",
    "\n",
    "    train_transform = Compose([\n",
    "        RandomRotate90(),\n",
    "        Flip(),\n",
    "    ])\n",
    "\n",
    "    # image_paths, mask_paths = image_paths[:20], mask_paths[:20] # overfitting\n",
    "    X_train, X_test, y_train, y_test = train_test_split(image_paths, mask_paths,  test_size=0.4, random_state=config.seed)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=config.seed)\n",
    "    # split X_test, y_test into validation and test, 50-50\n",
    "\n",
    "    train_dataset = BUSIDataset(image_paths=X_train, mask_paths=y_train, size=config.SIZE, transform=train_transform)\n",
    "    val_dataset = BUSIDataset(image_paths=X_val, mask_paths=y_val, size=config.SIZE, transform=None)\n",
    "    test_dataset = BUSIDataset(image_paths=X_test, mask_paths=y_test, size=config.SIZE, transform=None)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=False)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=False)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=False)\n",
    "\n",
    "    log = OrderedDict([\n",
    "        ('train_lr', []),\n",
    "        ('train_loss', []),\n",
    "        ('train_iou', []),\n",
    "        ('train_dice', []),\n",
    "        ('val_loss', []),\n",
    "        ('val_iou', []),\n",
    "        ('val_dice', []),\n",
    "    ])\n",
    "\n",
    "    best_dice = 0\n",
    "    trigger = 0\n",
    "    total_trained_epochs = 0\n",
    "    for epoch in range(config.epochs):\n",
    "        print('Epoch [%d/%d]' % (epoch, config.epochs))\n",
    "        total_trained_epochs += 1\n",
    "\n",
    "        # train for one epoch\n",
    "        train_log = train(train_loader, model, criterion, optimizer)\n",
    "        # evaluate on validation set\n",
    "        val_log = validate(val_loader, model, criterion)\n",
    "\n",
    "        if config.scheduler == 'CosineAnnealingLR':\n",
    "            scheduler.step()\n",
    "        elif config.scheduler == 'ReduceLROnPlateau':\n",
    "            scheduler.step(val_log['loss'])\n",
    "\n",
    "        print(f\"loss {train_log['loss']:.4f} - iou {train_log['iou']:.4f} - dice {train_log['dice']:.4f} \\\n",
    "                - val_loss {val_log['loss']:.4f} - val_iou {val_log['iou']:.4f} - val_dice {val_log['dice']:.4f}\") \n",
    "\n",
    "        print(train_log, val_log)\n",
    "        log['train_lr'].append(config.lr)\n",
    "        log['train_loss'].append(train_log['loss'])\n",
    "        log['train_iou'].append(train_log['iou'])\n",
    "        log['train_dice'].append(train_log['dice'])\n",
    "        log['val_loss'].append(val_log['loss'])\n",
    "        log['val_iou'].append(val_log['iou'])\n",
    "        log['val_dice'].append(val_log['dice'])\n",
    "\n",
    "        pd.DataFrame(log).to_csv('models/%s/log.csv' %\n",
    "                                    config.model, index=False)\n",
    "\n",
    "        trigger += 1\n",
    "\n",
    "        if val_log['dice'] > best_dice:\n",
    "            torch.save(model.state_dict(), 'models/%s/model.pth' %\n",
    "                        config.model)\n",
    "            best_dice = val_log['dice']\n",
    "            print(\"=> saved best model\")\n",
    "            trigger = 0\n",
    "\n",
    "        # early stopping\n",
    "        if config.early_stopping >= 0 and trigger >= config.early_stopping:\n",
    "            print(\"=> early stopping\")\n",
    "            break\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"Val Loss: {log['val_loss'][-1]:.4f} - Val IOU: {log['val_iou'][-1]:.4f} - Val Dice: {log['val_dice'][-1]:.4f}\")\n",
    "\n",
    "    model.load_state_dict(torch.load('models/%s/model.pth' % config.model))\n",
    "    test_log = validate(test_loader, model, criterion)\n",
    "    print(f\"Test loss {test_log['loss']:.4f} - Test IoU {test_log['iou']:.4f} - Test Dice {test_log['dice']:.4f}\")\n",
    "    test_log_df = pd.DataFrame({'model': [config.model], 'epochs': [total_trained_epochs], 'size': [config.SIZE], 'params': [num_params], 'test_dice': [test_log['dice']], 'test_iou': [test_log['iou']], 'test_loss': [test_log['loss']], 'seed' : [config.seed]})\n",
    "    # append test_log_df to test_log.csv\n",
    "    test_log_df.to_csv('test_log.csv', mode='a', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "model: Wavelet_UNet_All\n",
      "SIZE: 128\n",
      "batch_size: 32\n",
      "num_workers: 8\n",
      "n_channels: 1\n",
      "lr: 0.0001\n",
      "min_lr: 1e-05\n",
      "epochs: 50\n",
      "early_stopping: 50\n",
      "patience: 50\n",
      "base_dir: \n",
      "root_path: breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/\n",
      "semantic: False\n",
      "device: cuda:0\n",
      "classes: ['normal', 'benign', 'malignant']\n",
      "labels: ['cancer']\n",
      "num_classes: 1\n",
      "loss: BCEDiceLoss\n",
      "optimizer: Adam\n",
      "scheduler: CosineAnnealingLR\n",
      "weight_decay: 0.0001\n",
      "momentum: 0.9\n",
      "nesterov: False\n",
      "seed: 4\n",
      "--------------------\n",
      "===============================================================================================\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "├─DoubleConv: 1-1                             [-1, 64, 128, 128]        --\n",
      "|    └─Sequential: 2-1                        [-1, 64, 128, 128]        --\n",
      "|    |    └─Conv2d: 3-1                       [-1, 64, 128, 128]        576\n",
      "|    |    └─BatchNorm2d: 3-2                  [-1, 64, 128, 128]        128\n",
      "|    |    └─ReLU: 3-3                         [-1, 64, 128, 128]        --\n",
      "|    |    └─Conv2d: 3-4                       [-1, 64, 128, 128]        36,864\n",
      "|    |    └─BatchNorm2d: 3-5                  [-1, 64, 128, 128]        128\n",
      "|    |    └─ReLU: 3-6                         [-1, 64, 128, 128]        --\n",
      "├─Wavelet_Down_All: 1-2                       [-1, 128, 64, 64]         --\n",
      "|    └─Sequential: 2-2                        [-1, 128, 64, 64]         --\n",
      "|    |    └─WaveletDownsamplingAll: 3-7       [-1, 256, 64, 64]         --\n",
      "|    |    └─DoubleConv: 3-8                   [-1, 128, 64, 64]         442,880\n",
      "├─Wavelet_Down_All: 1-3                       [-1, 256, 32, 32]         --\n",
      "|    └─Sequential: 2-3                        [-1, 256, 32, 32]         --\n",
      "|    |    └─WaveletDownsamplingAll: 3-9       [-1, 512, 32, 32]         --\n",
      "|    |    └─DoubleConv: 3-10                  [-1, 256, 32, 32]         1,770,496\n",
      "├─Wavelet_Down_All: 1-4                       [-1, 512, 16, 16]         --\n",
      "|    └─Sequential: 2-4                        [-1, 512, 16, 16]         --\n",
      "|    |    └─WaveletDownsamplingAll: 3-11      [-1, 1024, 16, 16]        --\n",
      "|    |    └─DoubleConv: 3-12                  [-1, 512, 16, 16]         7,079,936\n",
      "├─Wavelet_Down_All: 1-5                       [-1, 512, 8, 8]           --\n",
      "|    └─Sequential: 2-5                        [-1, 512, 8, 8]           --\n",
      "|    |    └─WaveletDownsamplingAll: 3-13      [-1, 2048, 8, 8]          --\n",
      "|    |    └─DoubleConv: 3-14                  [-1, 512, 8, 8]           11,798,528\n",
      "├─Wavelet_Up: 1-6                             [-1, 256, 16, 16]         --\n",
      "|    └─WaveletUpsampling: 2-6                 [-1, 512, 16, 16]         --\n",
      "|    |    └─DWTInverse: 3-15                  [-1, 512, 16, 16]         --\n",
      "|    └─DoubleConv: 2-7                        [-1, 256, 16, 16]         --\n",
      "|    |    └─Sequential: 3-16                  [-1, 256, 16, 16]         5,899,776\n",
      "├─Wavelet_Up: 1-7                             [-1, 128, 32, 32]         --\n",
      "|    └─WaveletUpsampling: 2-8                 [-1, 256, 32, 32]         --\n",
      "|    |    └─DWTInverse: 3-17                  [-1, 256, 32, 32]         --\n",
      "|    └─DoubleConv: 2-9                        [-1, 128, 32, 32]         --\n",
      "|    |    └─Sequential: 3-18                  [-1, 128, 32, 32]         1,475,328\n",
      "├─Wavelet_Up: 1-8                             [-1, 64, 64, 64]          --\n",
      "|    └─WaveletUpsampling: 2-10                [-1, 128, 64, 64]         --\n",
      "|    |    └─DWTInverse: 3-19                  [-1, 128, 64, 64]         --\n",
      "|    └─DoubleConv: 2-11                       [-1, 64, 64, 64]          --\n",
      "|    |    └─Sequential: 3-20                  [-1, 64, 64, 64]          369,024\n",
      "├─Wavelet_Up: 1-9                             [-1, 64, 128, 128]        --\n",
      "|    └─WaveletUpsampling: 2-12                [-1, 64, 128, 128]        --\n",
      "|    |    └─DWTInverse: 3-21                  [-1, 64, 128, 128]        --\n",
      "|    └─DoubleConv: 2-13                       [-1, 64, 128, 128]        --\n",
      "|    |    └─Sequential: 3-22                  [-1, 64, 128, 128]        110,848\n",
      "├─OutConv: 1-10                               [-1, 1, 128, 128]         --\n",
      "|    └─Conv2d: 2-14                           [-1, 1, 128, 128]         65\n",
      "===============================================================================================\n",
      "Total params: 28,984,577\n",
      "Trainable params: 28,984,577\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 7.06\n",
      "===============================================================================================\n",
      "Input size (MB): 0.06\n",
      "Forward/backward pass size (MB): 85.12\n",
      "Params size (MB): 110.57\n",
      "Estimated Total Size (MB): 195.75\n",
      "===============================================================================================\n",
      "Total Images: 647, Masks: 647\n",
      "Epoch [0/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:14<00:00,  1.15s/it, loss=1.11, iou=0.208, dice=0.341]\n",
      "100%|██████████| 5/5 [00:02<00:00,  1.76it/s, loss=1.25, iou=0.0877, dice=0.161]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 1.1050 - iou 0.2079 - dice 0.3407                 - val_loss 1.2471 - val_iou 0.0877 - val_dice 0.1610\n",
      "OrderedDict({'loss': 1.1050330769155443, 'iou': 0.207873120487762, 'dice': 0.3406533061160655}) OrderedDict({'loss': 1.2470715923826823, 'iou': 0.08765481276793513, 'dice': 0.16104796032148788})\n",
      "=> saved best model\n",
      "Epoch [1/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:14<00:00,  1.11s/it, loss=1.03, iou=0.28, dice=0.434] \n",
      "100%|██████████| 5/5 [00:02<00:00,  1.81it/s, loss=1.38, iou=0.0975, dice=0.177]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 1.0258 - iou 0.2797 - dice 0.4345                 - val_loss 1.3816 - val_iou 0.0975 - val_dice 0.1773\n",
      "OrderedDict({'loss': 1.0257551663929654, 'iou': 0.2796768172773909, 'dice': 0.4344620264589046}) OrderedDict({'loss': 1.381576149962669, 'iou': 0.09748757820390058, 'dice': 0.17727373956103817})\n",
      "=> saved best model\n",
      "Epoch [2/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:14<00:00,  1.10s/it, loss=0.961, iou=0.373, dice=0.54] \n",
      "100%|██████████| 5/5 [00:02<00:00,  1.79it/s, loss=1.37, iou=0.147, dice=0.255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.9608 - iou 0.3725 - dice 0.5405                 - val_loss 1.3661 - val_iou 0.1474 - val_dice 0.2555\n",
      "OrderedDict({'loss': 0.9607649470112988, 'iou': 0.37252120043373477, 'dice': 0.5404727620005393}) OrderedDict({'loss': 1.3660640688829644, 'iou': 0.14735730114763532, 'dice': 0.25547576741343536})\n",
      "=> saved best model\n",
      "Epoch [3/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:14<00:00,  1.10s/it, loss=0.938, iou=0.385, dice=0.552]\n",
      "100%|██████████| 5/5 [00:02<00:00,  1.78it/s, loss=1.33, iou=0.153, dice=0.266]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.9384 - iou 0.3850 - dice 0.5522                 - val_loss 1.3296 - val_iou 0.1534 - val_dice 0.2656\n",
      "OrderedDict({'loss': 0.9384009076147964, 'iou': 0.3850045846777508, 'dice': 0.5521747577487527}) OrderedDict({'loss': 1.3295779131179633, 'iou': 0.15344828815621606, 'dice': 0.2656442762228287})\n",
      "=> saved best model\n",
      "Epoch [4/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:14<00:00,  1.10s/it, loss=0.919, iou=0.408, dice=0.577]\n",
      "100%|██████████| 5/5 [00:02<00:00,  1.84it/s, loss=1.42, iou=0.169, dice=0.287]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.9187 - iou 0.4076 - dice 0.5772                 - val_loss 1.4229 - val_iou 0.1686 - val_dice 0.2874\n",
      "OrderedDict({'loss': 0.9187479510749739, 'iou': 0.4076146787634587, 'dice': 0.5772300706765477}) OrderedDict({'loss': 1.422883579897326, 'iou': 0.16863669569693496, 'dice': 0.2874316599141005})\n",
      "=> saved best model\n",
      "Epoch [5/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 2/13 [00:02<00:12,  1.17s/it, loss=0.936, iou=0.362, dice=0.531]"
     ]
    }
   ],
   "source": [
    "modifications = [('UNet', 38), ('UNet', 25), ('UNet', 18), ('UNet', 9), ('Wavelet_UNet', 38), ('Wavelet_UNet', 25), ('Wavelet_UNet', 18), ('Wavelet_UNet', 9)]\n",
    "\n",
    "for (model, seed) in modifications:\n",
    "    config.model = model\n",
    "    config.seed = seed\n",
    "    set_seed(\n",
    "run_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "busi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
